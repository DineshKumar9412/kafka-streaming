KAFKS MYSQL CDC FINAL DOCUMENT ---- 27/7/2022

Debezium Connecter MYSQL
************************
https://sandeepkattepogu.medium.com/streaming-data-from-mysql-into-apache-kafka-db9b5468667e

install sublime-text
********************
https://linuxize.com/post/how-to-install-sublime-text-3-on-ubuntu-20-04/

INSTALL JAVA AND SET HOME PATH
*******************************
https://vitux.com/how-to-setup-java_home-path-in-ubuntu/

sudo apt-get install vim

sudo vi .bashrc 

export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

source .bashrc 

Downloading Debezium files
***************************
https://repo1.maven.org/maven2/io/debezium/


How to Install MYSQL and basic setup
*************************************
https://www.digitalocean.com/community/tutorials/how-to-install-mysql-on-ubuntu-20-04

PASSWORD ERROR
*************** 
https://exerror.com/failed-error-set-password-has-no-significance-for-user-rootlocalhost-as-the-authentication-method-used-doesnt-store-authentication-data-in-the-mysql-server/

Create DB Information 
**********************
sudo vi testdb.sql

-- Create the test database
CREATE DATABASE testDB;
GO
USE testDB;
-- Create some fruit
CREATE TABLE fruit (
id INTEGER ZEROFILL NOT NULL AUTO_INCREMENT,
fruit_name VARCHAR(255) NOT NULL,
num_sold INTEGER NOT NULL,
PRIMARY KEY(id) 
);
-- Insert test values
INSERT INTO fruit(fruit_name, num_sold)
VALUES ('Apple', 5);
INSERT INTO fruit(fruit_name, num_sold)
VALUES ('Pear', 10);
INSERT INTO fruit(fruit_name, num_sold)
VALUES ('Peach', 20);

sudo chmod 777 testdb.sql

mysql -u root -p < testdb.sql

Mysql Changes
**************
sudo vi /etc/mysql/my.cnf
[mysqld]
server-id = 42
log_bin = mysql-bin
binlog_row_image = full
binlog_format = row
expire_logs_days = 10
gtid_mode=on
enforce_gtid_consistency=on

interactive_timeout=600
wait_timeout=600
binlog_rows_query_log_events=on

Mysql grant all privileges
***************************
mysql -u root -p

create user and set password
*****************************
CREATE USER 'dbuser'@'%' IDENTIFIED BY 'Password1@';

grand all access
****************
GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON . TO 'dbuser'@'%';

ALTER USER 'dbuser'@'%' IDENTIFIED WITH mysql_native_password BY 'Password1@';

FLUSH PRIVILEGES;

Set the GTID Consistency and the GTID Mode
SET @@GLOBAL.ENFORCE_GTID_CONSISTENCY = OFF;
SET @@GLOBAL.ENFORCE_GTID_CONSISTENCY = ON;
SET @@GLOBAL.GTID_MODE = OFF;
SET @@GLOBAL.GTID_MODE = OFF_PERMISSIVE;
SET @@GLOBAL.GTID_MODE = ON_PERMISSIVE;

Before proceeding, make sure the following table shows a value of “0”
*********************************************************************
SHOW STATUS LIKE 'ONGOING_ANONYMOUS_TRANSACTION_COUNT';
SET @@GLOBAL.GTID_MODE = ON;
exit

sudo systemctl restart mysql


Kafka Setup Details
*********************

sudo chmod 777 kafka.sh

sudo ./kafka.sh


set java security
******************

https://www.oracle.com/in/java/technologies/javase-jce8-downloads.html

us = harikumar.r@oasys.co
pas = Oasys@123

sudo apt install unzip

unzip jce_policy-8.zip

sudo cp -r /home/harikumar/Downloads/UnlimitedJCEPolicyJDK8/* /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security
sudo cp -r /home/harikumar/Downloads/UnlimitedJCEPolicyJDK8/* /etc/java-8-openjdk-amd64/security

cd /usr/lib/jvm/java-8-openjdk-amd64/jre/lib/security
cd /etc/java-8-openjdk-amd64/security

sudo chmod 777 local_policy.jar US_export_policy.jar


Zookeeper ca-cert in zookeeper
*******************************

password == pem file == oasys
password == trust == qwertyu
password == keystore == asdfgh

openssl req -new -x509 -keyout ca-key -out ca-cert -days 3650

keytool -keystore kafka.zookeeper.truststore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.zookeeper.keystore.jks -alias zookeeper -validity 3650 -genkey -keyalg RSA -ext SAN=dns:localhost

keytool -keystore kafka.zookeeper.keystore.jks -alias zookeeper -certreq -file ca-request-zookeeper

openssl x509 -req -CA ca-cert -CAkey ca-key -in ca-request-zookeeper -out ca-signed-zookeeper -days 3650 -CAcreateserial

keytool -keystore kafka.zookeeper.keystore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.zookeeper.keystore.jks -alias zookeeper -import -file ca-signed-zookeeper


sudo rm -rf ca-cert.srl ca-request-zookeeper ca-signed-zookeeper


zookeeper-client ssl ca-cert
****************************
password == trust == qwertyu
password == keystore == asdfgh

keytool -keystore kafka.zookeeper-client.truststore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.zookeeper-client.keystore.jks -alias zookeeper-client -validity 3650 -genkey -keyalg RSA -ext SAN=dns:localhost

keytool -keystore kafka.zookeeper-client.keystore.jks -alias zookeeper-client -certreq -file ca-request-zookeeper-client

openssl x509 -req -CA ca-cert -CAkey ca-key -in ca-request-zookeeper-client -out ca-signed-zookeeper-client -days 3650 -CAcreateserial

keytool -keystore kafka.zookeeper-client.keystore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.zookeeper-client.keystore.jks -alias zookeeper-client -import -file ca-signed-zookeeper-client

cd ssl
sudo rm -rf ca-cert.srl ca-request-zookeeper-client ca-signed-zookeeper-client

server.properties ca-cert 
*************************

password == trust == qwertyu
password == keystore == asdfgh

keytool -keystore kafka.broker0.truststore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.broker0.keystore.jks -alias broker0 -validity 3650 -genkey -keyalg RSA -ext SAN=dns:localhost

keytool -keystore kafka.broker0.keystore.jks -alias broker0 -certreq -file ca-request-broker0

openssl x509 -req -CA ca-cert -CAkey ca-key -in ca-request-broker0 -out ca-signed-broker0 -days 3650 -CAcreateserial

keytool -keystore kafka.broker0.keystore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.broker0.keystore.jks -alias broker0 -import -file ca-signed-broker0

cd ssh
sudo rm -rf ca-cert.srl ca-request-broker0 ca-signed-broker0

server-1.properties ca-cert 
****************************

password == trust == qwertyu
password == keystore == asdfgh

keytool -keystore kafka.broker1.truststore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.broker1.keystore.jks -alias broker1 -validity 3650 -genkey -keyalg RSA -ext SAN=dns:localhost

keytool -keystore kafka.broker1.keystore.jks -alias broker1 -certreq -file ca-request-broker1

openssl x509 -req -CA ca-cert -CAkey ca-key -in ca-request-broker1 -out ca-signed-broker1 -days 3650 -CAcreateserial

keytool -keystore kafka.broker1.keystore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.broker1.keystore.jks -alias broker1 -import -file ca-signed-broker1

cd ssh
sudo rm -rf ca-cert.srl ca-request-broker1 ca-signed-broker1

server-2.properties ca-cert 
****************************

password == trust == qwertyu
password == keystore == asdfgh

keytool -keystore kafka.broker2.truststore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.broker2.keystore.jks -alias broker2 -validity 3650 -genkey -keyalg RSA -ext SAN=dns:localhost

keytool -keystore kafka.broker2.keystore.jks -alias broker2 -certreq -file ca-request-broker2

openssl x509 -req -CA ca-cert -CAkey ca-key -in ca-request-broker2 -out ca-signed-broker2 -days 3650 -CAcreateserial

keytool -keystore kafka.broker2.keystore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.broker2.keystore.jks -alias broker2 -import -file ca-signed-broker2

cd ssh
sudo rm -rf ca-cert.srl ca-request-broker2 ca-signed-broker2

kafka producer ssl ca-cert
****************************
password == trust == qwertyu
password == keystore == asdfgh

keytool -keystore kafka.producer.truststore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.producer.keystore.jks -alias producer -validity 3650 -genkey -keyalg RSA -ext SAN=dns:localhost

keytool -keystore kafka.producer.keystore.jks -alias producer -certreq -file ca-request-producer

openssl x509 -req -CA ca-cert -CAkey ca-key -in ca-request-producer -out ca-signed-producer -days 3650 -CAcreateserial

keytool -keystore kafka.producer.keystore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.producer.keystore.jks -alias producer -import -file ca-signed-producer

cd ssh
sudo rm -rf ca-cert.srl ca-request-producer ca-signed-producer


kafka consumer ssl ca-cert
****************************
password == trust == qwertyu
password == keystore == asdfgh

keytool -keystore kafka.consumer.truststore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.consumer.keystore.jks -alias consumer -validity 3650 -genkey -keyalg RSA -ext SAN=dns:localhost

keytool -keystore kafka.consumer.keystore.jks -alias consumer -certreq -file ca-request-consumer

openssl x509 -req -CA ca-cert -CAkey ca-key -in ca-request-consumer -out ca-signed-consumer -days 3650 -CAcreateserial

keytool -keystore kafka.consumer.keystore.jks -alias ca-cert -import -file ca-cert

keytool -keystore kafka.consumer.keystore.jks -alias consumer -import -file ca-signed-consumer

cd ssh
sudo rm -rf ca-cert.srl ca-request-consumer ca-signed-consumer



sudo bin/zookeeper-server-start.sh config/zookeeper.properties
sudo bin/kafka-server-start.sh config/server.properties 
sudo bin/kafka-server-start.sh config/server-1.properties 
sudo bin/kafka-server-start.sh config/server-2.properties 
sudo bin/connect-distributed.sh config/connect-distributed.properties

ps -ef | grep zookeeper
ps -ef | grep kafka

          (or)
              
sudo bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
sudo bin/kafka-server-start.sh -daemon config/server.properties
sudo bin/kafka-server-start.sh -daemon config/server-1.properties
sudo bin/kafka-server-start.sh -daemon config/server-2.properties
sudo bin/connect-distributed.sh -daemon config/connect-distributed.properties




TEST ZOOKEEPER AND ITS CLIENTS
**********************************
**********************************

sudo bin/zookeeper-shell.sh localhost:2182 -zk-tls-config-file config/zookeeper-client.properties

[sudo] password for harikumar: 
Connecting to localhost:2182
Welcome to ZooKeeper!
JLine support is disabled

WATCHER::

WatchedEvent state:SyncConnected type:None path:null

ls /brokers/ids
[0, 1, 2]




check topic in kafka
********************
sudo bin/kafka-topics.sh --list --bootstrap-server localhost:9092 --command-config config/ssl.config

IF You want to delete topic
****************************
sudo vi config/server.properties

## past this line below
delete.topic.enable=true  

sudo bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic quickstart-events --command-config config/ssl.config

create topic comm
*****************
sudo bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --topic first-topics --command-config config/ssl.config --partitions 2 --replication-factor 3

describe topic
**************
sudo bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --command-config config/ssl.config
sudo bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic first-topics --command-config config/ssl.config

producer
*********
sudo bin/kafka-console-producer.sh --broker-list localhost:9092 --topic first-topics --producer.config config/producer.properties

consumer
********
sudo bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093,localhost:9094 --topic first-topics --consumer.config config/consumer.properties --from-beginning

sudo bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-topic --from-beginning --consumer.config config/consumer.properties



create user for sasl_ssl
*************************

bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config 'SCRAM-SHA-256=[password=admin-secret],SCRAM-SHA-512=[password=admin-secret]' --entity-type users --entity-name admin --command-config config/ssl.config


bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config 'SCRAM-SHA-512=[password=admin-secret]' --entity-type users --entity-name admin --command-config config/ssl.config


bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config 'SCRAM-SHA-512=[password=producer-secret]' --entity-type users --entity-name my-producer --command-config config/ssl.config


bin/kafka-configs.sh --bootstrap-server localhost:9092 --alter --add-config 'SCRAM-SHA-512=[password=consumer-secret]' --entity-type users --entity-name my-consumer --command-config config/ssl.config




ACL operations permission:
**************************

Normal local kafka producer and consumer ACL 
********************************************
Producer:
**********

sudo bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2182 --zk-tls-config-file config/zookeeper-client.properties --add --allow-principal User:my-producer --operation WRITE --operation DESCRIBE --operation DESCRIBECONFIGS --topic first-topics
                               or
sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config config/ssl.config --add -allow-principal User:my-producer --operation WRITE --operation DESCRIBE --operation DESCRIBECONFIGS --topic first-topic

Consumer:
*********

sudo bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2182 --zk-tls-config-file config/zookeeper-client.properties --add --allow-principal User:my-consumer --operation READ --operation DESCRIBE --topic first-topics

sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config config/ssl.config --add -allow-principal User:my-consumer --operation READ --operation DESCRIBE  --topic first-topic

Adding the SSL group for reading from the consumer
***************************************************

sudo bin/kafka-acls.sh --authorizer-properties zookeeper.connect=localhost:2182 --zk-tls-config-file config/zookeeper-client.properties --add --allow-principal User:my-consumer --operation READ --group ssl-consumer-group

sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config config/ssl.config --add -allow-principal User:my-consumer --operation READ --group ssl-consumer-group


Mysql producer and consumer ACL
********************************
kafka cluster Topic access
**************************

Cluster ACL 
************
sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --cluster --add --allow-principal User:my-producer --operation ALL --command-config config/ssl.config

Consumer Topic ACL 
*******************

sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config config/ssl.config --add -allow-principal User:my-producer --producer --topic kafka-cluster

sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config config/ssl.config --add -allow-principal User:my-producer --producer --topic dbhistory.fulfillment

sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config config/ssl.config --add -allow-principal User:my-producer --producer --topic fruitserver

sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config config/ssl.config --add -allow-principal User:my-producer --producer --topic fruitserver.testDB.fruit

Consumer Topic ACL
*******************

sudo bin/kafka-acls.sh --bootstrap-server localhost:9092 --command-config config/ssl.config --add -allow-principal User:my-consumer --consumer  --topic fruitserver.testDB.fruit --group ssl-consumer-group



Curl Request
*************

curl -i -X POST -H "Accept:application/json" -H "Content-Type:application/json" localhost:8083/connectors/ -d '{ "name": "test-connector", "config": { "connector.class": "io.debezium.connector.mysql.MySqlConnector", "database.hostname": "localhost", "database.port": "3306", "database.user": "root", "database.password": "root@123", "database.server.id": "8115", "database.allowPublicKeyRetrieval":"true", "database.server.name": "fruitserver", "database.whitelist": "testDB", "database.history.kafka.bootstrap.servers": "localhost:9092", "database.history.kafka.topic": "dbhistory.fulfillment", "include.schema.changes": "true","table.whitelist":"testDB.fruit","database.history.consumer.sasl.mechanism":"SCRAM-SHA-512", "database.history.consumer.security.protocol":"SASL_SSL", "database.history.consumer.ssl.key.password":"asdfgh", "database.history.consumer.ssl.keystore.location":"/home/user/kafka/ssl/kafka.consumer.keystore.jks", "database.history.consumer.ssl.keystore.password":"asdfgh", "database.history.consumer.ssl.truststore.location":"/home/user/kafka/ssl/kafka.consumer.truststore.jks", "database.history.consumer.ssl.truststore.password":"qwerty", "database.history.consumer.sasl.jaas.config":"org.apache.kafka.common.security.scram.ScramLoginModule required username=\"my-consumer\",password=\"consumer-secret\";", "database.history.producer.sasl.mechanism":"SCRAM-SHA-512", "database.history.producer.security.protocol":"SASL_SSL", "database.history.producer.ssl.key.password":"asdfgh", "database.history.producer.ssl.keystore.location":"/home/user/kafka/ssl/kafka.producer.keystore.jks", "database.history.producer.ssl.keystore.password":"asdfgh", "database.history.producer.ssl.truststore.location":"/home/user/kafka/ssl/kafka.producer.truststore.jks", "database.history.producer.ssl.truststore.password":"qwerty", "database.history.producer.sasl.jaas.config":"org.apache.kafka.common.security.scram.ScramLoginModule required username=\"my-producer\" password=\"producer-secret\";", "database.history.sasl.mechanism":"SCRAM-SHA-512", "database.history.security.protocol":"SASL_SSL", "database.history.ssl.key.password":"asdfgh", "database.history.ssl.keystore.location":"/home/user/kafka/ssl/kafka.broker0.keystore.jks", "database.history.ssl.keystore.password":"asdfgh", "database.history.ssl.truststore.location":"/home/user/kafka/ssl/kafka.broker0.truststore.jks", "database.history.ssl.truststore.password":"qwerty", "database.history.sasl.jaas.config":"org.apache.kafka.common.security.scram.ScramLoginModule required username=\"admin\" password=\"admin-secret\";" } }';

Curl Delete commant
********************

curl -X DELETE http://localhost:8083/connectors/test-connector

